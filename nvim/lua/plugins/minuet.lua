-- https://github.com/milanglacier/minuet-ai.nvim
return {
  'milanglacier/minuet-ai.nvim',
  config = function()
    require('minuet').setup {
      cmp = {
        enable_auto_complete = false,
      },
      blink = {
        enable_auto_complete = true,
      },
      provider = 'openai',
      -- the maximum total characters of the context before and after the cursor
      -- 16000 characters typically equate to approximately 4,000 tokens for
      -- LLMs.
      context_window = 16000,
      -- when the total characters exceed the context window, the ratio of
      -- context before cursor and after cursor, the larger the ratio the more
      -- context before cursor will be used. This option should be between 0 and
      -- 1, context_ratio = 0.75 means the ratio will be 3:1.
      context_ratio = 0.60,
      throttle = 300, -- only send the request every x milliseconds, use 0 to disable throttle.
      -- debounce the request in x milliseconds, set to 0 to disable debounce
      debounce = 80,
      -- Control notification display for request status
      -- Notification options:
      -- false: Disable all notifications (use boolean false, not string "false")
      -- "debug": Display all notifications (comprehensive debugging)
      -- "verbose": Display most notifications
      -- "warn": Display warnings and errors only
      -- "error": Display errors only
      notify = 'warn',
      -- The request timeout, measured in seconds. When streaming is enabled
      -- (stream = true), setting a shorter request_timeout allows for faster
      -- retrieval of completion items, albeit potentially incomplete.
      -- Conversely, with streaming disabled (stream = false), a timeout
      -- occurring before the LLM returns results will yield no completion items.
      request_timeout = 5,
      -- If completion item has multiple lines, create another completion item
      -- only containing its first line. This option only has impact for cmp and
      -- blink. For virtualtext, no single line entry will be added.
      add_single_line_entry = true,
      -- The number of completion items encoded as part of the prompt for the
      -- chat LLM. For FIM model, this is the number of requests to send. It's
      -- important to note that when 'add_single_line_entry' is set to true, the
      -- actual number of returned items may exceed this value. Additionally, the
      -- LLM cannot guarantee the exact number of completion items specified, as
      -- this parameter serves only as a prompt guideline.
      n_completions = 4,
      -- Defines the length of non-whitespace context after the cursor used to
      -- filter completion text. Set to 0 to disable filtering.
      --
      -- Example: With after_cursor_filter_length = 3 and context:
      --
      -- "def fib(n):\n|\n\nfib(5)" (where | represents cursor position),
      --
      -- if the completion text contains "fib", then "fib" and subsequent text
      -- will be removed. This setting filters repeated text generated by the
      -- LLM. A large value (e.g., 15) is recommended to avoid false positives.
      after_cursor_filter_length = 0,
      -- proxy port to use
      proxy = nil,
      provider_options = {
        openai = {
          model = 'gpt-4.1-nano',
          stream = true,
          api_key = 'OPENAI_API_KEY',

          -- 1) System prompt – picked at runtime per filetype
          system = {
            prompt = function()
              local ft = vim.bo.filetype
              if ft == 'python' then
                return 'You are the backend of an AI-powered code completion engine specialised in Python. Provide idiomatic Python code and comment completions.'
              elseif ft == 'bash' or ft == 'sh' then
                return 'You are the backend of an AI-powered code completion engine specialised in Bash. Provide POSIX-compliant shell script lines and comments that match the existing indentation.'
              elseif ft == 'lua' then
                return 'You are the backend of an AI-powered code completion engine specialised in Lua. Provide clean Lua code and comment completions following the user indentation.'
              else
                return require('minuet.config').default_system.prompt
              end
            end,
          },

          -- 2) One-shot few-shot examples – one per supported language
          few_shots = function()
            local ft = vim.bo.filetype
            if ft == 'python' then
              return {
                {
                  role = 'user',
                  content = [[
# language: python
<contextAfterCursor>

fib(5)
<contextBeforeCursor>
def fibonacci(n):
    <cursorPosition>]],
                },
                {
                  role = 'assistant',
                  content = [[
    '''
    Recursive Fibonacci implementation
    '''
    if n < 2:
        return n
    return fibonacci(n - 1) + fibonacci(n - 2)
<endCompletion>]],
                },
              }
            elseif ft == 'bash' or ft == 'sh' then
              return {
                {
                  role = 'user',
                  content = [[
# language: bash
<contextAfterCursor>

say_hello
<contextBeforeCursor>
function say_hello() {
    <cursorPosition>
}]],
                },
                {
                  role = 'assistant',
                  content = [[
    echo "Hello, world!"
<endCompletion>]],
                },
              }
            elseif ft == 'lua' then
              return {
                {
                  role = 'user',
                  content = [[
# language: lua
<contextAfterCursor>

fib(5)
<contextBeforeCursor>
local function fib(n)
    <cursorPosition>
end]],
                },
                {
                  role = 'assistant',
                  content = [[
    if n < 2 then
        return n
    end
    return fib(n - 1) + fib(n - 2)
<endCompletion>]],
                },
              }
            else
              return require('minuet.config').default_few_shots
            end
          end,

          -- 3) Chat-input section – override only the {{language}} placeholder
          chat_input = {
            language = function()
              return ('# language: %s'):format(vim.bo.filetype)
            end,
          },

          optional = {
            temperature = 0.4,
            top_p = 0.95,
            max_tokens = 120,
          },
        },
      },
    }
  end,
}
